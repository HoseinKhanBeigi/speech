<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech to Text</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 600px;
            width: 100%;
        }

        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2rem;
        }

        .api-key-section {
            margin-bottom: 20px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 10px;
        }

        .api-key-section label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #333;
            font-size: 0.9rem;
        }

        .api-key-section input {
            width: 100%;
            padding: 10px;
            border: 2px solid #e9ecef;
            border-radius: 8px;
            font-size: 0.9rem;
            font-family: monospace;
        }

        .api-key-section input:focus {
            outline: none;
            border-color: #667eea;
        }

        .api-key-section .info {
            margin-top: 8px;
            font-size: 0.8rem;
            color: #666;
        }

        .api-key-section .info a {
            color: #667eea;
            text-decoration: none;
        }

        .api-key-section .info a:hover {
            text-decoration: underline;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        button {
            padding: 15px 30px;
            font-size: 1rem;
            border: none;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .start-btn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .start-btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .start-btn:active:not(:disabled) {
            transform: translateY(0);
        }

        .stop-btn {
            background: #ff6b6b;
            color: white;
        }

        .stop-btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(255, 107, 107, 0.4);
        }

        .stop-btn:active:not(:disabled) {
            transform: translateY(0);
        }

        .clear-btn {
            background: #95a5a6;
            color: white;
        }

        .clear-btn:hover {
            background: #7f8c8d;
            transform: translateY(-2px);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }

        .status {
            text-align: center;
            margin-bottom: 20px;
            font-size: 0.9rem;
            color: #666;
            min-height: 20px;
        }

        .status.listening {
            color: #667eea;
            font-weight: 600;
            animation: pulse 1.5s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
        }

        .text-output {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 10px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            font-size: 1rem;
            line-height: 1.6;
            color: #333;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        .text-output:empty::before {
            content: "Your transcribed text will appear here...";
            color: #999;
            font-style: italic;
        }

        .mic-icon {
            width: 20px;
            height: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Speech to Text</h1>
        
        <div class="api-key-section">
            <label for="apiKey">AssemblyAI API Key:</label>
            <input type="password" id="apiKey" placeholder="Enter your API key" />
            <div class="info">
                Get your free API key at <a href="https://www.assemblyai.com/" target="_blank">assemblyai.com</a> (Free tier available)
            </div>
        </div>

        <div class="file-upload-section" style="margin-bottom: 20px; padding: 15px; background: #f8f9fa; border-radius: 10px;">
            <label for="audioFile" style="display: block; margin-bottom: 8px; font-weight: 600; color: #333; font-size: 0.9rem;">Or Upload Audio File:</label>
            <input type="file" id="audioFile" accept="audio/*" style="width: 100%; padding: 10px; border: 2px solid #e9ecef; border-radius: 8px; font-size: 0.9rem;" />
            <button id="transcribeFileBtn" class="start-btn" style="margin-top: 10px; width: 100%; justify-content: center;">
                Transcribe File
            </button>
        </div>
        
        <div class="controls">
            <button id="startBtn" class="start-btn">
                <svg class="mic-icon" viewBox="0 0 24 24" fill="currentColor">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
                Start Listening
            </button>
            <button id="stopBtn" class="stop-btn" disabled>
                Stop Listening
            </button>
            <button id="clearBtn" class="clear-btn">
                Clear
            </button>
        </div>

        <div class="status" id="status">Enter your API key to get started</div>

        <div class="text-output" id="output"></div>
    </div>

    <script type="module">
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const transcribeFileBtn = document.getElementById('transcribeFileBtn');
        const audioFileInput = document.getElementById('audioFile');
        const output = document.getElementById('output');
        const status = document.getElementById('status');
        const apiKeyInput = document.getElementById('apiKey');

        let socket = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isListening = false;

        // Load API key from localStorage if available
        const savedApiKey = localStorage.getItem('assemblyai_api_key');
        if (savedApiKey) {
            apiKeyInput.value = savedApiKey;
        }

        // Save API key when changed
        apiKeyInput.addEventListener('input', () => {
            localStorage.setItem('assemblyai_api_key', apiKeyInput.value);
        });

        async function startListening() {
            const apiKey = apiKeyInput.value.trim();
            
            if (!apiKey) {
                status.textContent = 'Please enter your AssemblyAI API key';
                status.style.color = '#ff6b6b';
                return;
            }

            try {
                status.textContent = 'Connecting...';
                status.style.color = '#666';

                // Get user's microphone
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Create MediaRecorder
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });

                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                // Get temporary token from AssemblyAI
                const response = await fetch('https://api.assemblyai.com/v2/realtime/token', {
                    method: 'POST',
                    headers: {
                        'authorization': apiKey,
                        'content-type': 'application/json'
                    },
                    body: JSON.stringify({
                        expires_in: 3600
                    })
                });

                if (!response.ok) {
                    const error = await response.text();
                    throw new Error(`Failed to get token: ${error}`);
                }

                const { token } = await response.json();

                // Connect to AssemblyAI WebSocket
                socket = new WebSocket(`wss://api.assemblyai.com/v2/realtime/ws?sample_rate=16000&token=${token}`);

                socket.onopen = () => {
                    isListening = true;
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    status.textContent = 'ðŸŽ¤ Listening...';
                    status.classList.add('listening');
                    status.style.color = '';

                    // Start recording
                    mediaRecorder.start(250); // Send data every 250ms
                };

                socket.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    
                    if (data.message_type === 'SessionBegins') {
                        console.log('Session started');
                    } else if (data.message_type === 'PartialTranscript') {
                        // Show interim results
                        const currentText = output.textContent.replace(/\[.*?\]/g, '').trim();
                        output.textContent = currentText + (currentText ? ' ' : '') + `[${data.text}]`;
                    } else if (data.message_type === 'FinalTranscript') {
                        // Remove interim results and add final transcript
                        const currentText = output.textContent.replace(/\[.*?\]/g, '').trim();
                        output.textContent = currentText + (currentText ? ' ' : '') + data.text + ' ';
                    }
                };

                socket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    status.textContent = 'Connection error. Please try again.';
                    status.classList.remove('listening');
                    status.style.color = '#ff6b6b';
                    stopListening();
                };

                socket.onclose = () => {
                    if (isListening) {
                        status.textContent = 'Connection closed. Click Start to reconnect.';
                        status.classList.remove('listening');
                    }
                };

                // Send audio data to WebSocket
                mediaRecorder.addEventListener('dataavailable', async (event) => {
                    if (event.data.size > 0 && socket && socket.readyState === WebSocket.OPEN) {
                        const reader = new FileReader();
                        reader.onload = () => {
                            const base64Audio = reader.result.split(',')[1];
                            socket.send(JSON.stringify({
                                audio_data: base64Audio
                            }));
                        };
                        reader.readAsDataURL(event.data);
                    }
                });

            } catch (error) {
                console.error('Error starting recognition:', error);
                status.textContent = `Error: ${error.message}`;
                status.style.color = '#ff6b6b';
                stopListening();
            }
        }

        function stopListening() {
            isListening = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
            status.textContent = 'Stopped';
            status.classList.remove('listening');
            status.style.color = '#666';

            if (socket) {
                socket.close();
                socket = null;
            }

            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                mediaRecorder = null;
            }
        }

        // File transcription function
        async function transcribeFile() {
            const apiKey = apiKeyInput.value.trim();
            const file = audioFileInput.files[0];
            
            if (!apiKey) {
                status.textContent = 'Please enter your AssemblyAI API key';
                status.style.color = '#ff6b6b';
                return;
            }
            
            if (!file) {
                status.textContent = 'Please select an audio file';
                status.style.color = '#ff6b6b';
                return;
            }

            try {
                transcribeFileBtn.disabled = true;
                status.textContent = 'Uploading file...';
                status.style.color = '#666';

                // Upload file to AssemblyAI
                const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
                    method: 'POST',
                    headers: {
                        'authorization': apiKey
                    },
                    body: file
                });

                if (!uploadResponse.ok) {
                    throw new Error('Failed to upload file');
                }

                const { upload_url } = await uploadResponse.json();

                status.textContent = 'Transcribing...';

                // Start transcription
                const transcriptResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
                    method: 'POST',
                    headers: {
                        'authorization': apiKey,
                        'content-type': 'application/json'
                    },
                    body: JSON.stringify({
                        audio_url: upload_url,
                        speech_model: 'universal'
                    })
                });

                if (!transcriptResponse.ok) {
                    throw new Error('Failed to start transcription');
                }

                const { id } = await transcriptResponse.json();

                // Poll for results
                let transcript = null;
                while (!transcript || transcript.status !== 'completed') {
                    await new Promise(resolve => setTimeout(resolve, 3000));
                    
                    const statusResponse = await fetch(`https://api.assemblyai.com/v2/transcript/${id}`, {
                        headers: {
                            'authorization': apiKey
                        }
                    });

                    transcript = await statusResponse.json();

                    if (transcript.status === 'error') {
                        throw new Error(transcript.error || 'Transcription failed');
                    }

                    if (transcript.status === 'processing' || transcript.status === 'queued') {
                        status.textContent = `Status: ${transcript.status}...`;
                    }
                }

                // Display result
                output.textContent = transcript.text;
                status.textContent = 'Transcription complete!';
                status.style.color = '#667eea';
                transcribeFileBtn.disabled = false;

            } catch (error) {
                console.error('Error transcribing file:', error);
                status.textContent = `Error: ${error.message}`;
                status.style.color = '#ff6b6b';
                transcribeFileBtn.disabled = false;
            }
        }

        startBtn.addEventListener('click', startListening);
        stopBtn.addEventListener('click', stopListening);
        transcribeFileBtn.addEventListener('click', transcribeFile);
        clearBtn.addEventListener('click', () => {
            output.textContent = '';
        });
    </script>
</body>
</html>
